---
title: "group_assignment"
# format:
#   docx:
#     toc: true
#     number-sections: true
fig-dpi: 600
---

# Introduction

The primary objective of this project is to conduct a comprehensive empirical analysis of a selected basket of equities to evaluate their performance characteristics and risk exposures. Our project is structured into three main pillars:

First, we perform a **descriptive analysis** of individual stock returns. We examine the distributional properties of returns, specifically looking for deviations from normality through skewness and kurtosis, and assess time-varying risk metrics. Given the distinct economic phases within our sample period, we place particular emphasis on analyzing how volatility and Sharpe ratios have evolved over time.

Second, we apply **Modern Portfolio Theory (MPT)** to construct and compare different investment strategies. We contrast a "naive" diversification strategy (Equal-Weighted Portfolio, $1/N$) against a sophisticated Markowitz Mean-Variance Optimization (Tangency Portfolio). Next, we perform a regime-based subperiod analysis, where we evaluate how these strategies performed during the pre-COVID era, the pandemic liquidity rally, and the recent inflationary rate-hike cycle. This allows us to answer whether complex optimization adds value compared to simple diversification during periods of market stress.

Finally, we analyze the drivers of expected returns using **linear factor models**. We employ the Single-Index (Market) Model to estimate systematic risk ($\beta$) and the Fama-French Three-Factor Model to decompose returns into market, size (SMB), and value (HML) premiums. This regression analysis aims to determine how much of the portfolio's performance is attributable to broad market movements versus idiosyncratic factor exposure.

# Data and Methodology

## Data Sourcing and Processing

Our dataset comprises monthly closing prices for a selected basket of equities spanning a ten-year observation period from **August 29, 2014, to August 30, 2024**. Unfortunately, we were not able to obtain the data for the time frame from August 30, 2024 to September 2025. The raw stock data is sourced from CRSP, adjusted for corporate actions such as stock splits and dividends.

To establish a benchmark for the risk-free rate $R_f$, we utilize the 3-Month Treasury Bill Secondary Market Rate (Ticker: DTB3), sourced from the Federal Reserve Economic Data (FRED) database. As the raw data provides annualized percentages, we convert these into monthly risk-free rates using the following transformation:

$R_{f, monthly} = (1 + R_{f, annual})^{1/12} - 1$

For the multifactor analysis, we utilize the **Fama-French Three-Factor** dataset (Market, SMB, HML), obtained from Kenneth French’s data library.

## Return Calculation and Index Construction

A critical methodological distinction is made between logarithmic (continuously compounded) and simple (arithmetic) returns to ensure mathematical consistency across different analyses.

1.  **Logarithmic Returns (**$r_t$): calculated as $ln(P_t / P_{t-1})$. These are utilized for the time-series analysis, descriptive statistics, and the reconstruction of price indices, as they possess the property of time-additivity.

2.  **Arithmetic Returns (**$R_t$): calculated as $(P_t - P_{t-1}) / P_{t-1}$. These are utilized for portfolio weighting, Sharpe Ratio calculations, and regression analysis, as the weighted average of log returns does not equal the log return of a portfolio.

To visualize cumulative performance, we construct normalized price indices for all assets, initialized at a base value of 100 on August 29, 2014. These "simulated" price paths allow for direct visual comparison of relative performance regardless of absolute share price.

## Statistical Framework and Measures

We perform a descriptive analysis of the distributional properties of returns. Beyond the first two moments (Mean and Variance), we examine higher-order moments to detect deviations from normality:

-   **Skewness:** To measure the asymmetry of the return distribution.

-   **Kurtosis:** To measure the "fatness" of tails (leptokurtosis), indicating the probability of extreme events.

-   **Maximum Drawdown:** Calculated as the largest percentage decline from a previous peak to a subsequent trough, serving as a metric for downside risk.

## Portfolio Optimization Strategy

We contrast two distinct portfolio construction methodologies:

1.  **Naive Diversification (**$1/N$): An Equal-Weighted (EW) portfolio where every asset is assigned a weight of $w_i = 1/N$, rebalanced monthly. This serves as our baseline strategy.

2.  **Markowitz Mean-Variance Optimization:** We construct the **Tangency Portfolio**, which maximizes the Sharpe Ratio. The optimization problem is solved using the `ROI` (R Optimization Infrastructure) solver under the following constraints:

    -   **Full Investment:** $\sum w_i = 1$

    -   **Long-Only:** $w_i \ge 0$ (No short selling allowed)

The optimization determines the ex-post optimal weights that would have generated the highest risk-adjusted return over the selected decade.

## Market Regimes and Subperiod Analysis

To assess the robustness of our strategies, we segment the decade into three distinct macroeconomic regimes:

1.  **Pre-COVID (Aug 2014 – Dec 2019):** Characterized by low volatility and steady growth.

2.  **Pandemic Era (Jan 2020 – Dec 2021):** Defined by the initial crash followed by a liquidity-driven rally (Quantitative Easing).

3.  **Inflation & Rate Hikes (Jan 2022 – Aug 2024):** Characterized by rising interest rates and high inflation.

## Factor Models and Regression

Finally, we analyze the drivers of systematic risk using linear regression models. We employ the Single-Index Market Model using the NASDAQ Composite as the market proxy:

\$\$R\_{i,t} - R\_{f,t} = \\alpha_i + \\beta_i(R\_{M,t} - R\_{f,t}) + \\epsilon\_{i,t}\$\$

Additionally, we apply the Fama-French Three-Factor Model to control for size and value premiums:

\$\$R\_{i,t} - R\_{f,t} = \\alpha_i + \\beta\_{mkt}(R\_{M,t} - R\_{f,t}) + \\beta\_{SMB}SMB_t + \\beta\_{HML}HML_t + \\epsilon\_{i,t}\$\$

This allows us to decompose returns into market risk ($\beta$), size exposure ($SMB$), and value exposure ($HML$), isolating the varying degrees of alpha ($\alpha$) generated by each stock.

```{r echo = FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(readxl)
library(ggplot2)
library(knitr)
library(moments)
library(slider)
library(tidyquant)
library(PortfolioAnalytics)
library(PerformanceAnalytics)
library(ROI)
library(ROI.plugin.quadprog)
library(ROI.plugin.glpk)
library(writexl)
library(broom)
```

```{r echo = FALSE, message=FALSE, warning=FALSE}
data_raw <- read_xlsx("data/stocks.xlsx")
# glimpse(data_raw)

# risikoloser zins
invisible(getSymbols("DTB3", src = "FRED"))

# risikoloser zins in richtiges format bringen
dtb3 <- tibble(
  date = index(DTB3),
  rate = as.numeric(DTB3)
) %>%
  filter(!is.na(rate)) %>%
  filter(date >= as.Date("2014-08-29"), date <= as.Date("2024-08-30")) %>%
  mutate(
    rF_annual = rate / 100,
    rF_monthly = (1 + rF_annual)^(1/12)-1,
    month = as.Date(format(date, "%Y-%m-01"))
    ) %>%
  group_by(month) %>%
  slice_tail(n = 1) %>%
  ungroup() %>%
  select(date, rF_monthly)
  
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Funkion für Darstellung der Dataframes | kann man ignorieren

dataframe_fancy <- function(df) {
  tibble(
    Variable = names(df),
    Datentyp = sapply(df, class),
    Wert = sapply(df, function(x) {
      as.character(x[!is.na(x)][1])
    })
  ) %>%
    knitr::kable(
      col.names = c("Variable", "Datentyp", "Wert"),
      align = c("l", "l", "l")
    )
}

```

```{r echo = FALSE}
# dataframe für returns

returns <- data_raw %>%
  select(permno = PERMNO,
         ticker = `Ticker Symbol`,
         company = `Company Name`,
         date = `Names Date`,
         returns = Returns) %>%
  arrange(ticker, date) %>%
  mutate(returns_log = log(1 + returns))
  
# dataframe_fancy(returns)


```

```{r echo=FALSE}
ticker = returns %>% distinct(ticker)

prices <- returns %>%
  group_by(ticker) %>%
  arrange(date) %>%
  mutate(prices = 100 * exp(cumsum(returns_log)) / first(exp(cumsum(returns_log)))) %>%
  arrange(ticker, date) %>%
  ungroup()

# dataframe_fancy(prices)
```

# Descriptive Analysis of Individual Stocks

```{r echo=FALSE}


# plot für alle aktien
ggplot(prices, aes(x = date, y = prices, color = ticker)) +
  geom_line(linewidth = 0.5) +
  scale_y_log10() +
  labs(title = "Stock Prices",
       x = "Date",
       y = "Prices log") +
  theme_minimal() +
  theme(legend.position = "bottom", legend.title = element_blank())
```

**Figure 1** displays the cumulative performance of the selected stocks from 2014 to 2024, normalized to a base of 100 on a logarithmic scale. The decade is characterized by a strong bull market; despite volatility, every asset generated positive returns, with values ranging between 200 and over 1000 (representing 2x to 10x capital appreciation).

Top performers like Eli Lilly (LLY) and large-cap technology stocks decoupled from the rest of the basket. Two major market shocks are clearly visible across all series: the sharp, synchronized V-shaped crash during the onset of COVID-19 in early 2020, and the prolonged valuation compression during the 2022 inflationary bear market.

## Return and Risk Characteristics

```{r echo=FALSE}
max_drawdown <- prices %>%
  group_by(ticker) %>%
  mutate(
    running_max = cummax(prices),
    drawdown = prices / running_max - 1
  ) %>%
  summarise(max_drawdown = min(drawdown, na.rm=TRUE))

statistics_stocks <- returns %>%
  group_by(ticker) %>%
  summarise(
    mean_return = exp(mean(returns_log, na.rm = TRUE)) - 1,
    sd_return   = sd(returns, na.rm = TRUE),
    min_return  = min(returns, na.rm = TRUE),
    max_return  = max(returns, na.rm = TRUE)
  ) %>%
  left_join(max_drawdown, by = "ticker")

statistics_stocks %>%
  mutate(
    mean_return = ((1 + mean_return)^12 - 1) * 100,
    sd_return = sd_return * 100 * sqrt(12),
    min_return = min_return * 100,
    max_return = max_return * 100,
    max_drawdown = max_drawdown * 100
  ) %>%
  kable(col.names = c("Ticker", "Ø Return Geo. (% p.a.)", "Std.Dev. (%) p.a.", "Minimum (%)", "Maximum (%)", "Max Drawdown (%)"),
        digits = 2)
```

**Table 1** presents a comprehensive summary of the annualized risk and return metrics for each individual portfolio constituent, including geometric returns, volatility, and maximum drawdowns. Eli Lilly (LLY) stands out as the top performer, delivering an annualized geometric return of 34.09%, significantly outpacing the broader group. The technology sector also exhibited strong momentum, with Apple (AAPL) and Netflix (NFLX) generating annualized returns of 28.86% and 27.53%, respectively. Conversely, traditional defensive stocks and financials lagged behind; Emerson (EMR) and Coca-Cola (KO) posted single-digit annualized returns of roughly 8-10%, reflecting their mature, lower-growth profiles.

The Standard Deviation column highlights the cost of high returns. Netflix (NFLX) was the most volatile asset with an annualized standard deviation of 42.41%, coupled with a severe Maximum Drawdown of -74.67%, indicating that investors had to endure a loss of nearly three-quarters of their capital at the worst point in the cycle. Amazon (AMZN) similarly shows high risk, with volatility over 31% and a drawdown exceeding 50%.

Notably, Costco (COST) and Eli Lilly (LLY) demonstrate remarkable efficiency. Despite being top-tier performers in terms of returns, their maximum drawdowns were contained at approximately -20% lower than many underperforming stocks like Schwab (SCHW) or Ebay (EBAY). This suggests that LLY and COST provided the most favorable asymmetry between upside capture and downside protection over the decade.

## Distributional Properties of Returns

```{r echo=FALSE, message=FALSE, warning=FALSE}
distribution_stocks <- returns %>%
  group_by(ticker) %>%
  summarise(
    skewness = skewness(returns_log, na.rm = TRUE),
    kurtosis = kurtosis(returns_log, na.rm = TRUE)
  ) %>%
  mutate(skewness_int = case_when(
      skewness > 0 ~ "positively skewed",
      skewness == 0 ~ "symmetric",
      skewness < 0 ~ "negatively skewed"
      ),
      kurtosis_int = case_when(
        kurtosis < 0 ~ "platykurtic",
        kurtosis > 0 ~ "leptokurtic",
        kurtosis == 0 ~ "norm. distributed"
      )
      )

distribution_stocks %>%
  select(ticker, skewness, skewness_int, kurtosis, kurtosis_int) %>%
  kable(col.names = c("Ticker", "Skewness", "Interpretation", "Excess Kurtosis", "Interpretation"))
```

**Table 2** examines the higher-order moments of the return distributions to assess deviations from normality a critical check since many financial models (including Mean-Variance Optimization) assume normally distributed returns.

The results reveal a mixed profile, though significant negative skewness is prevalent in high-volatility names. Netflix (NFLX) exhibits the most pronounced negative skew of -1.32, followed by Schwab (SCHW) at -0.93. This "left-tail" asymmetry indicates that these stocks are prone to frequent small gains punctuated by occasional, severe sharp drops (crash risk). Conversely, eBay (EBAY) displays the highest positive skewness (0.38), suggesting a distribution tilted towards positive outliers.

The majority of the basket exhibits leptokurtosis (positive excess kurtosis), implying "fat tails" where extreme events occur more frequently than a normal distribution would predict. Netflix is again the outlier with an extreme excess kurtosis of 6.96, confirming its historical susceptibility to massive price shocks.

Interestingly, Apple (AAPL) and Eli Lilly (LLY) are classified as platykurtic (excess kurtosis \< 0), indicating a "thinner" tailed distribution with fewer extreme outliers relative to the mean than the standard normal curve.

## Time-Varying Risk and Performance

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Leider fehlende Werte von rF_monthly für 2024-03-28 ; 2018-03-29 ; 2021-05-28
# Letzten Tag im Monat genommen

excess_return <- returns %>%
  mutate(month = as.Date(format(date, "%Y-%m-01"))) %>%
  left_join(
    dtb3 %>%
      mutate(month = as.Date(format(date, "%Y-%m-01"))),
    by = "month"
  ) %>%
  mutate(excess_return = returns - rF_monthly)


sharpe_ratio_rolling <- excess_return %>%
  group_by(ticker) %>%
  arrange(date.x) %>%
  mutate(
    roll_mean_excess = slide_dbl(
      excess_return,
      mean,
      .before = 11,
      .complete = TRUE
    ),
    roll_sd = slide_dbl(
      excess_return,
      sd,
      .before = 11,
      .complete = TRUE
    ),
    sharpe_ratio_rolling = (roll_mean_excess / roll_sd) * sqrt(12)
  ) %>%
  ungroup()

ggplot(sharpe_ratio_rolling, aes(x = date.x, y = sharpe_ratio_rolling, group = ticker, color = ticker)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red", alpha = 0.7) +
  geom_line(alpha = 0.5) +
  labs(title = "12 month Rolling Sharpe Ratios", x = "Date", y = "SR (annualized)") +
  theme_minimal() +
  theme(legend.position = "bottom", legend.title = element_blank())

```

**Figure 2** illustrates the instability of risk-adjusted returns over time via 12-month rolling Sharpe Ratios. The plot is characterized by distinct cyclicality, most notably the synchronized regime shift in 2022, where the entire basket dropped below the zero line as falling asset prices collided with rising risk-free rates.

Despite these systematic headwinds, idiosyncratic outliers are visible. Eli Lilly (LLY) significantly decoupled from the group in late 2023, achieving Sharpe Ratios exceeding 3.0, indicating that strong corporate fundamentals can occasionally override broader market stress.

## Total Set of Stocks (Equally Weighted)

```{r echo=FALSE}
# ew = equal weights
portfolio_ew <- excess_return %>%
  group_by(date.x) %>%
  summarise(
    portfolio_ew_return = mean(returns, na.rm = TRUE),
    portfolio_ew_excess_return = mean(excess_return, na.rm = TRUE)
  ) %>%
  ungroup()

portfolio_ew_prices <- portfolio_ew %>%
  arrange(date.x) %>%
  mutate(portfolio_price = 100 * exp(cumsum(log(1 + portfolio_ew_return))) / first(exp(cumsum(log(1 + portfolio_ew_return)))))

# dataframe_fancy(portfolio_ew)
# dataframe_fancy(portfolio_ew_prices)
```

```{r echo=FALSE}
ggplot() +
  # Einzelaktien (grau, Hintergrund)
  geom_line(
    data = prices,
    aes(x = date, y = prices, group = ticker),
    color = "grey70",
    alpha = 0.4,
    linewidth = 0.5
  ) +
  # Portfolio (schwarz, Vordergrund)
  geom_line(
    data = portfolio_ew_prices,
    aes(x = date.x, y = portfolio_price),
    color = "black",
    linewidth = 1.2
  ) +
  scale_y_log10() +
  labs(
    title = "Stock Performance vs. Equal-Weighted Portfolio",
    subtitle = "Grey lines = individual stocks, black line = equal-weighted portfolio",
    x = "Date",
    y = "Index (start = 100)"
  ) +
  theme_minimal()



```

**Figure 3** visualizes the performance of a naive diversification strategy ($1/N$) against the backdrop of its individual constituents. The bold black line represents the Equal-Weighted Portfolio, while the grey lines represent the individual stock price paths.

The chart effectively demonstrates the "smoothing" effect of diversification. While individual stocks exhibit jagged, erratic volatility, with some skyrocketing and others stagnating, the equal-weighted portfolio cuts through the noise, tracking the central tendency of the group. By holding all assets, the portfolio eliminates exposure to single-stock idiosyncratic risk, ensuring that a crash in one name (e.g., Netflix in 2022) is offset by stability or gains in others.

Despite not holding only the "best" winners, the naive strategy proved highly effective. The portfolio index grew from 100 to approximately 600 over the decade, representing a six-fold increase in capital. This confirms that simply maintaining exposure to this high-quality basket, without attempting to time the market or pick winners, was sufficient to generate substantial long-term wealth.

```{r echo = FALSE}
returns_wide <- returns %>%
  group_by(ticker, date) %>%
  summarise(returns = mean(returns, na.rm = TRUE),
            .groups = "drop") %>%
  pivot_wider(
    names_from = ticker,
    values_from = returns
  ) %>%
  arrange(date)

cor_matrix <- returns_wide %>%
  select(-date) %>%
  cor(use = "pairwise.complete.obs")

cor_long <- cor_matrix %>%
  as.data.frame() %>%
  rownames_to_column("Stock1") %>%
  pivot_longer(
    -Stock1,
    names_to = "Stock2",
    values_to = "Correlation"
  )

ggplot(cor_long, aes(x = Stock2, y = Stock1, fill = Correlation)) +
  geom_tile(color = "white", linewidth = 0.4) +
  geom_text(
    aes(label = sprintf("%.2f", Correlation)),
    size = 1.5,
    color = "black"
  ) +
  scale_fill_gradient2(
    low = "#d73027",
    mid = "#FFFFFF",
    high = "#1a9850",
    midpoint = 0,
    limits = c(-1, 1),
    name = "Correlation"
  ) +
  labs(
    title = "Correlation Matrix of Monthly Stock Returns"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_blank(),
    panel.grid = element_blank()
  )
```

**Figure 4** displays the pairwise correlation coefficients between the monthly returns of all constituents. The heatmap is predominantly green, indicating positive correlations across the board—a typical characteristic of equity markets where systematic risk factors (interest rates, GDP growth) affect most assets simultaneously.

Strong intra-sector relationships are clearly visible. The highest correlations are found between companies with similar business models, confirming significant shared risk exposure:

-   Defense: Lockheed Martin (LMT) and General Dynamics (GD) exhibit a correlation of 0.67, the highest in the matrix, reflecting their joint sensitivity to geopolitical events and government spending.

-   Big Tech: Alphabet (GOOGL) and Amazon (AMZN) show a strong link at 0.62, driven by their overlapping exposure to the digital economy and consumer sentiment.

The most critical insight for portfolio construction is the behavior of Eli Lilly (LLY). The row for LLY is noticeably paler than the rest, indicating it is virtually uncorrelated with the broader basket. It even exhibits negative correlations with cyclical stocks like Old Dominion Freight Line (-0.11) and Schwab (-0.03). This lack of correlation suggests that LLY’s returns were driven almost entirely by idiosyncratic factors (e.g., drug pipeline success) rather than the market cycle, making it an exceptionally powerful diversifier in this specific portfolio.

## Return and Risk Characteristics of Equally Weighted Portfolio

```{r echo = FALSE}
statistics_portfolio_ew <- portfolio_ew %>%
  summarise(
    # Arithmetisch für SR
    mean_return_arith = mean(portfolio_ew_return, na.rm = TRUE) * 12 * 100,
    # Geometrisch für Performance Vergleich
    mean_return_geo = ((1 + (exp(mean(log(1 + portfolio_ew_return), na.rm = TRUE)) - 1))^12 - 1) * 100,
    sd_return   = sd(portfolio_ew_return, na.rm = TRUE) * sqrt(12) * 100,
    min_return  = min(portfolio_ew_return, na.rm = TRUE) * 100,
    max_return  = max(portfolio_ew_return, na.rm = TRUE) * 100
  )

portfolio_ew_drawdown <- portfolio_ew_prices %>%
  arrange(date.x) %>%
  mutate(
    running_max = cummax(portfolio_price),
    drawdown = portfolio_price / running_max - 1
  ) %>%
  summarise(max_drawdown = min(drawdown, na.rm =TRUE)) * 100

statistics_portfolio_ew <- statistics_portfolio_ew %>%
  mutate(max_drawdown = portfolio_ew_drawdown$max_drawdown)

statistics_portfolio_ew <- statistics_portfolio_ew %>%
  mutate(
    sharpe_ratio = (
      #Excess Return existiert schon (sicherer) + annualisiert
      mean(portfolio_ew$portfolio_ew_excess_return, na.rm = TRUE) /
      sd(portfolio_ew$portfolio_ew_return, na.rm = TRUE) 
    ) * sqrt(12)
  )



statistics_portfolio_ew %>%
  kable(
    col.names = c(
      "Ø Return Arith. (% p.a.)",
      "Ø Return Geo. (% p.a.)", 
      "Volatility (% p.a.)",
      "Min Month (%)",
      "Max Month (%)",
      "Max Drawdown (%)",
      "Sharpe Ratio (annual)"
    ),
    digits = 2
  )

```

**Table 3** summarizes the performance metrics of the Equal-Weighted ($1/N$) strategy, underlining the power of diversification. By simply averaging across the basket, the portfolio achieved an annualized Geometric Mean Return of 21.44%, driving the six-fold capital appreciation observed earlier.

Most importantly, the strategy effectively suppressed risk. The annualized Volatility was reduced to 15.73%, lower than even the most stable individual stock (Coca-Cola) and significantly below high-growth names like Netflix. This risk reduction also protected capital during downturns, with a Maximum Drawdown of -19.21%, meaning the portfolio never lost more than one-fifth of its value. The resulting Sharpe Ratio of 1.22 confirms that the naive approach delivered highly efficient risk-adjusted returns.

### Rolling Volatility of Equally Weighted Portfolio

\[PLATZHALTER\]

```{r echo = FALSE, warning=FALSE}
portfolio_ew_vola_rolling <- portfolio_ew %>%
  arrange(date.x) %>%
  mutate(
    roll_sd = slide_dbl(
      portfolio_ew_return,
      sd,
      .before = 11,
      .complete = TRUE
    ),
    roll_sd_annual = roll_sd * sqrt(12)
  )

ggplot(portfolio_ew_vola_rolling,
       aes(x = date.x, y = roll_sd_annual)) +
  geom_line(color = "black", linewidth = 1) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "12-Month Rolling Volatility – Equally-Weighted Portfolio",
    x = "Date",
    y = "Volatility (% p.a.)"
  ) +
  theme_minimal()


```

**Figure 5** plots the 12-month rolling volatility, demonstrating that the portfolio's risk profile is highly non-stationary. While the long-term average volatility is approximately 15.7%, the portfolio oscillated between periods of extreme calm and significant market stress.

The period around 2017–2018 represents a historical "low volatility regime," where annualized risk dipped below 10%. This stands in stark contrast to the two major stress events of the decade: the sharp, sudden spike during the COVID-19 onset in early 2020, and the sustained peak in 2022–2023. Notably, the 2022 inflationary bear market drove volatility to a decade-high exceeding 25%, reflecting the intense uncertainty surrounding interest rate policy during that window.

### Rolling Sharpe Ratio of Equally Weighted Portfolio

```{r echo = FALSE, warning=FALSE}
portfolio_ew_sharpe_rolling <- portfolio_ew %>%
  arrange(date.x) %>%
  mutate(
    roll_mean_excess = slide_dbl(
      portfolio_ew_excess_return,
      mean,
      .before = 11,
      .complete = TRUE
    ),
    roll_sd = slide_dbl(
      portfolio_ew_excess_return,
      sd,
      .before = 11,
      .complete = TRUE
    ),
    sharpe_12m = (roll_mean_excess / roll_sd) * sqrt(12)
  )

ggplot(portfolio_ew_sharpe_rolling,
       aes(x = date.x, y = sharpe_12m)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red", alpha = 0.7) +
  geom_line(color = "black", linewidth = 1) +
  labs(
    title = "12-Month Rolling Sharpe Ratio – Equal-Weighted Portfolio",
    x = "Date",
    y = "Sharpe Ratio (annualized)"
  ) +
  theme_minimal()

```

**Figure 6** illustrates the risk-adjusted efficiency of the portfolio over time. The 12-month rolling Sharpe Ratio reveals extreme cyclicality, with the metric oscillating between a historic high of over 5.0 and a low of approximately -0.5.

The chart identifies a "Golden Era" around 2017, where low volatility combined with steady gains produced exceptional risk-adjusted returns. In contrast, the 2022 inflationary regime stands out as the most challenging period; it is the only sustained interval where the Sharpe Ratio remained negative, indicating that the portfolio failed to outperform the risk-free rate for nearly a full year. A robust recovery is visible in 2024, with ratios climbing back towards 2.0.

### Subperiod Analyis of Equally Weighted Portfolio

```{r echo=FALSE, message=FALSE, warning=FALSE}
plot_data <- portfolio_ew_prices %>%
  mutate(Phase = case_when(
    date.x < "2020-01-01" ~ "1. Pre-COVID",
    date.x < "2022-01-01" ~ "2. Pandemic (QE)",
    TRUE                  ~ "3. Inflation (Rates)"
  ))

ggplot(plot_data, aes(x = date.x, y = portfolio_price, color = Phase, group = 1)) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = as.Date("2020-02-01"), linetype = "dotted", color = "darkred") + 
  geom_vline(xintercept = as.Date("2022-01-01"), linetype = "dotted", color = "blue") +    
  
  scale_color_manual(values = c(
    "1. Pre-COVID" = "grey60", 
    "2. Pandemic (QE)" = "#1a9850",  # Grün (Rallye)
    "3. Inflation (Rates)" = "black" # Aktuell
  )) +
  labs(
    title = "Equal-Weighted Portfolio: 3-Phase Regime Analysis",
    subtitle = "Separating Pre-Crisis, Pandemic Liquidity, and Rate Hike Era",
    x = "Date",
    y = "Portfolio Value (Base = 100)"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

portfolio_ew_sub <- portfolio_ew %>%
  mutate(
    period = case_when(
      date.x < as.Date("2020-01-01") ~ "1. Pre-COVID (2014–2019)",
      date.x < as.Date("2022-01-01") ~ "2. Pandemic (2020–2021)",
      TRUE                           ~ "3. Rate Hikes (2022–2024)"
    )
  )

portfolio_ew_stats_sub <- portfolio_ew_sub %>%
  group_by(period) %>%
  summarise(
    mean_return_arith = mean(portfolio_ew_return, na.rm = TRUE) * 12 * 100,
    mean_return_geo   = ((1 + (exp(mean(log(1 + portfolio_ew_return), na.rm = TRUE)) - 1))^12 - 1) * 100,
    volatility_pa     = sd(portfolio_ew_return, na.rm = TRUE) * sqrt(12) * 100,
    sharpe_ratio      = (mean(portfolio_ew_excess_return, na.rm = TRUE) /
                         sd(portfolio_ew_return, na.rm = TRUE)) * sqrt(12),
    .groups = "drop"
  )

portfolio_ew_dd_sub <- portfolio_ew_prices %>%
  mutate(
    period = case_when(
      date.x < as.Date("2020-01-01") ~ "1. Pre-COVID (2014–2019)",
      date.x < as.Date("2022-01-01") ~ "2. Pandemic (2020–2021)",
      TRUE                           ~ "3. Rate Hikes (2022–2024)"
    )
  ) %>%
  group_by(period) %>%
  summarise(
    max_drawdown = min(portfolio_price / cummax(portfolio_price) - 1, na.rm = TRUE) * 100,
    .groups = "drop"
  )

portfolio_ew_table_sub <- portfolio_ew_stats_sub %>%
  left_join(portfolio_ew_dd_sub, by = "period") %>%
  mutate(across(where(is.numeric), ~ round(.x, 2)))

kable(
  portfolio_ew_table_sub,
  col.names = c(
    "Period",
    "Ø Return Arith. (% p.a.)",
    "Ø Return Geo. (% p.a.)",
    "Volatility (% p.a.)",
    "Sharpe Ratio (annual)",
    "Max Drawdown (%)"
  ),
  caption = "Detailed Regime Analysis: Impact of Rates and Inflation"
)
```

To isolate the impact of macroeconomic conditions, **Figure 7** segments the portfolio’s performance into three distinct regimes: Pre-COVID (Grey), the Pandemic Liquidity era (Green), and the Inflation/Rate Hike cycle (Black).

The contrast between the regimes is stark. The Pandemic period (2020–2021) was the most explosive, driven by unprecedented monetary stimulus. During this window, the portfolio generated a massive Geometric Return of 33.09% with the highest risk efficiency (Sharpe Ratio 1.72).

Conversely, the Rate Hike era (2022–2024) marked a clear deterioration in performance dynamics. As the "black line" illustrates, this phase began with a sharp correction. Volatility surged to a period-high of 18.62%, while geometric returns compressed to 14.68%. Consequently, the Sharpe Ratio collapsed to 0.62, quantifying how rising risk-free rates and falling asset prices combined to drastically erode the risk premium compared to the "easy money" era.

# Portfolio formation

```{r echo=FALSE, message=FALSE, warning=FALSE}
rF_portfolio_chart = mean(dtb3$rF_monthly, na.rm = TRUE)

# Portfolioanalyse mit PortfolioAnalytics
R <- xts(
  returns_wide %>% select(-date),
  order.by = returns_wide$date
)


# portfolio objekt erstellen
port <- portfolio.spec(colnames(R))

# Voll investieren, shortselling erlaubt
port <- add.constraint(port, type = "full_investment")
port <- add.constraint(port, type = "long_only")

# objectives definieren
port <- add.objective(port, type = "risk", name = "StdDev")
port <- add.objective(port, type = "return", name = "mean")

# efficient frontier berechnen
ef <- create.EfficientFrontier(
  R = R,
  portfolio = port,
  type = "mean-StdDev",
  n.portfolios = 50
)

port_sr <- add.objective(
  port,
  type = "risk_adjusted_return",
  name = "SharpeRatio",
  arguments = list(Rf = rF_portfolio_chart)
)

# maxST = TRUE! um marktportfolio zu bestimmen
tan <- optimize.portfolio(
  R = R,
  portfolio = port_sr,
  optimize_method = "ROI",
  maxSR = TRUE
)


chart.EfficientFrontier(
  ef,
  chart.tangent = TRUE,
  match.col = "StdDev",
  risk.col = "StdDev",
  return.col = "mean",
  chart.assets = TRUE,
  chart.CML = TRUE,
  rf = rF_portfolio_chart,
  col = "darkred"
)

weights_tangential <- extractWeights(tan) %>% 
  as.data.frame() %>% 
  rownames_to_column("Ticker") %>% 
  rename(Weight = ".") %>% 
  arrange(desc(Weight))

# Zweispaltige Darstellung der Tabelle
h <- ceiling(nrow(weights_tangential)/2)
weights_split <- cbind(
  weights_tangential[1:h, ], 
  weights_tangential[(h+1):nrow(weights_tangential), ][1:h, ]
)

kable(
  weights_split, 
  digits = 4, 
  caption = "Tangency Portfolio Weights (Optimized)",
  col.names = c("Ticker", "Weight", "Ticker", "Weight")
)


tan_returns_xts <- Return.portfolio(R, weights = extractWeights(tan))

tan_stats <- data.frame(
  Portfolio = "Tangency (Optimized)",
  Mean_Arith_PA = mean(tan_returns_xts, na.rm=TRUE) * 12 * 100,
  Mean_Geo_PA   = (prod(1 + tan_returns_xts)^(12/nrow(tan_returns_xts)) - 1) * 100,
  Vol_PA        = sd(tan_returns_xts, na.rm=TRUE) * sqrt(12) * 100,
  Sharpe_Annual = (mean(tan_returns_xts - rF_portfolio_chart, na.rm=TRUE) / 
                   sd(tan_returns_xts, na.rm=TRUE)) * sqrt(12)
)

ew_stats <- data.frame(
  Portfolio = "Equal Weighted (Naive)",
  Mean_Arith_PA = statistics_portfolio_ew$mean_return_arith,
  Mean_Geo_PA   = statistics_portfolio_ew$mean_return_geo,
  Vol_PA        = statistics_portfolio_ew$sd_return,
  Sharpe_Annual = statistics_portfolio_ew$sharpe_ratio
)

comparison_table <- bind_rows(ew_stats, tan_stats) %>%
  mutate(across(where(is.numeric), round, 2))

kable(
  comparison_table,
  col.names = c("Portfolio Strategy", "Ø Return Arith. (% p.a.)", "Ø Return Geo. (% p.a.)", "Volatility (% p.a.)", "Sharpe Ratio"),
  caption = "Performance Comparison: Naive Diversification (1/N) vs. Markowitz Optimization"
)


```

**Figure 8** visualizes the Efficient Frontier, the set of optimal portfolios that offer the highest expected return for a defined level of risk. The individual stocks (open circles) all lie below this curve, illustrating that holding single assets is inefficient compared to a diversified combination.

The optimization algorithm, tasked with maximizing the Sharpe Ratio, constructed a highly concentrated Tangency Portfolio. Contrary to a traditional diversified approach, the model allocated 36.91% of capital to a single stock: Eli Lilly (LLY). This is illustrated in **Table 5.**

This extreme allocation confirms our earlier correlation analysis; because LLY was virtually uncorrelated with the rest of the basket, the optimizer treated it as a unique source of alpha. Significant weights were also assigned to defensive/low-beta names like Lockheed Martin (14.56%) and Costco (14.54%). Interestingly, "Big Tech" giants like Apple, Amazon, and Google received zero weight, as their high correlation with each other offered no marginal diversification benefit.

**Table 6** quantifies the value of this optimization. The Tangency Portfolio dominated the naive strategy on every metric: it delivered a higher Geometric Return (27.73% vs. 21.44%) while simultaneously achieving *lower* Volatility (14.92% vs. 15.73%).

The result is a superior Sharpe Ratio of 1.62 (vs. 1.22 for the Equal-Weighted), proving that mathematically, the "free lunch" of diversification is maximized not by holding everything, but by holding the *right* uncorrelated assets.

## Performance of Optimized Portfolio vs Single Stocks

```{r echo=FALSE, message=FALSE, warning=FALSE}
portfolio_op_return_plot <- Return.portfolio(
  R,
  weights = extractWeights(tan),
  rebalance_on = NA
)
colnames(portfolio_op_return_plot) <- "Tangency Portfolio"

portfolio_ew_xts <- xts(
  portfolio_ew$portfolio_ew_return,
  order.by = portfolio_ew$date.x
)
colnames(portfolio_ew_xts) <- "Equal Weighted"

plot_data <- merge(portfolio_op_return_plot, portfolio_ew_xts, R)["2014-08-29/2024-08-30"]


n_stocks <- ncol(R)

my_colors <- c("black", "darkred", rep("lightgrey", n_stocks))

my_lwd <- c(2, 2, rep(0.8, n_stocks))

my_lty <- c(1, 2, rep(1, n_stocks))

charts.PerformanceSummary(
  R = plot_data,
  main = "Portfolio Performance vs Single Stocks",
  colorset = my_colors,
  lwd = my_lwd,
  lty = my_lty,
  legend.loc = NULL 
)
```

**Figure 9** contrasts the cumulative wealth generation of the Optimized Tangency Portfolio (Black) against the Naive Equal-Weighted Strategy (Red) and the universe of individual stocks (Grey).

The optimization demonstrated superior capital appreciation. The Tangency Portfolio ended the decade with a cumulative return exceeding 10x (a +1000% gain), significantly separating itself from the Naive strategy, which finished near 6x. While one single stock (Eli Lilly) outperformed the portfolio, the optimized strategy surpassed the vast majority of individual names without assuming single-stock concentration risk.

Crucially, the bottom panel highlights the strategy's defensive value. While individual stocks frequently suffered catastrophic drawdowns of -40% to -60%, particularly during the 2022 crash, the Optimized Portfolio’s drawdowns were visibly shallower, successfully capturing market upside while smoothing out volatility.

## Subperiod Analysis of Optimized Portfolio

```{r echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

portfolio_opt_sub <- tibble(
  d = as.Date(index(portfolio_op_return_plot)),
  ret = as.numeric(portfolio_op_return_plot)
) %>%
  mutate(month = floor_date(d, "month")) %>%
  left_join(
    dtb3 %>% mutate(month = floor_date(date, "month")),
    by = "month"
  ) %>%
  mutate(
    excess = ret - rF_monthly,
    
    period = case_when(
      d < as.Date("2020-01-01") ~ "1. Pre-COVID (2014–2019)",
      d < as.Date("2022-01-01") ~ "2. Pandemic (2020–2021)",
      TRUE                      ~ "3. Rate Hikes (2022–2024)"
    )
  )


plot_data_opt <- portfolio_opt_sub %>%
  arrange(d) %>%
  mutate(price = 100 * cumprod(1 + ret))

p <- ggplot(plot_data_opt, aes(x = d, y = price)) +
  geom_line(color = "grey60", linewidth = 1) + 
  geom_line(aes(color = period, group = 1), linewidth = 1) + 
  geom_vline(xintercept = as.Date("2020-02-01"), linetype = "dotted", color = "darkred") + 
  geom_vline(xintercept = as.Date("2022-01-01"), linetype = "dotted", color = "blue") +
  scale_color_manual(values = c(
    "1. Pre-COVID (2014–2019)" = "grey60", 
    "2. Pandemic (2020–2021)" = "#1a9850", 
    "3. Rate Hikes (2022–2024)" = "black"
  )) +
  labs(
    title = "Optimized Portfolio: Regime Analysis",
    subtitle = "Performance across different market regimes",
    x = "Date", y = "Index (Base = 100)", color = "Regime"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

print(p)

opt_stats <- portfolio_opt_sub %>%
  group_by(period) %>%
  summarise(
    mean_return_arith = mean(ret, na.rm = TRUE) * 12 * 100,
    mean_return_geo   = ((1 + (exp(mean(log(1 + ret), na.rm = TRUE)) - 1))^12 - 1) * 100,
    volatility_pa     = sd(ret, na.rm = TRUE) * sqrt(12) * 100,
    sharpe_ratio      = (mean(excess, na.rm = TRUE) / sd(ret, na.rm = TRUE)) * sqrt(12),
    .groups = "drop"
  )

opt_dd <- portfolio_opt_sub %>%
  group_by(period) %>%
  mutate(
    price_index = 100 * cumprod(1 + ret),
    drawdown = price_index / cummax(price_index) - 1
  ) %>%
  summarise(max_drawdown = min(drawdown, na.rm = TRUE) * 100, .groups = "drop")

portfolio_opt_table_sub <- opt_stats %>%
  left_join(opt_dd, by = "period") %>%
  mutate(across(where(is.numeric), round, 2))



ew_labeled  <- portfolio_ew_table_sub  %>% 
  mutate(Strategy = "Equal Weighted (1/N)")

opt_labeled <- portfolio_opt_table_sub %>% 
  mutate(Strategy = "Optimized (Tangency)")

final_comparison <- bind_rows(ew_labeled, opt_labeled) %>%
  
  # Reihenfolge der Strategien explizit festlegen
  mutate(
    Strategy = factor(
      Strategy,
      levels = c("Optimized (Tangency)", "Equal Weighted (1/N)")
    )
  ) %>%
  
  mutate(across(where(is.numeric), round, 2)) %>%
  
  # Sortieren: erst Periode, dann Strategie-Reihenfolge
  arrange(period, Strategy) %>%
  
  # Spalten: Periode ganz vorne
  select(
    Period = period, 
    Strategy,
    `Ø Geo Return` = mean_return_geo, 
    Volatility = volatility_pa, 
    Sharpe = sharpe_ratio, 
    MaxDD = max_drawdown
  )

kable(
  final_comparison,
  caption = "Strategy Performance by Market Regime (Stacked Comparison)",
  align = c("l", "l", "c", "c", "c", "c")
)
```

**Figure 10 and Table 7** break down the performance of the Tangency Portfolio across the three economic regimes, revealing a stark divergence in the final phase.

During the "Pre-COVID" and "Pandemic" eras, the optimization added incremental value. In the Pandemic liquidity rally, the Tangency portfolio captured a stunning Geometric Return of 40.43%, significantly outpacing the Equal-Weighted strategy (33.09%) while maintaining lower volatility.

The true value of the optimization emerged during the "Rate Hike" regime (Black line). While the naive portfolio struggled with a Sharpe Ratio of just 0.62, the Optimized Portfolio maintained a robust Sharpe Ratio of 1.29.

Most notably, the optimized strategy generated double the returns (32.68% vs. 14.68%) of the naive approach during this stress period. This resilience is directly attributable to the portfolio's composition: the heavy allocation to Eli Lilly (which rallied on idiosyncratic news) and the exclusion of interest-rate-sensitive Big Tech stocks allowed the portfolio to largely ignore the 2022 bear market. This is confirmed by the maximum drawdown: the optimized portfolio lost only -7.67% in this period, compared to -17.36% for the equal-weighted basket.

# Regression

To understand the drivers of performance, we move beyond simple return statistics to factor attribution. We employ linear regression to decompose the returns of each stock into **systematic risk** (exposure to broad market factors) and **idiosyncratic alpha** (stock-specific performance).

## Market Model

To measure the risk of each stock, we used the Single-Index Market Model. This regression compares individual stock returns ($R_{i}$) against the NASDAQ Composite index ($R_{m}$). The goal is to separate risk into two parts: market-driven risk (Beta) and company-specific return (Alpha). The formula used is:

\$$R_{i,t} = \alpha_i + \beta_i R_{m,t} + \epsilon_{i,t}$\$

```{r echo=FALSE, message=FALSE, warning=FALSE}
# marktdaten laden | https://fred.stlouisfed.org/series/NASDAQXCMP

market_raw <- read_xlsx("data/market.xlsx", sheet = "Daily")


# returns berechnen
returns_market <- market_raw %>%
  mutate(month = as.Date(format(observation_date, "%Y-%m-01"))) %>%
  group_by(month) %>%
  slice_tail(n=1) %>%
  ungroup() %>%
  select(month, observation_date, NASDAQXCMP) %>%
  mutate(return_market = NASDAQXCMP / lag(NASDAQXCMP) -1, date = observation_date) %>%
  select(month, return_market) %>%
  drop_na()

returns_wide_monthly <- returns_wide %>%
  mutate(month = floor_date(date, "month")) %>%
  select(-date) 

returns_reg <- returns_market %>%
  left_join(returns_wide_monthly, by = "month") %>%
  drop_na()


# Regression

stocks <- setdiff(names(returns_reg), c("month", "return_market"))

reg_output <- lapply(stocks, function(s) {
  model <- lm(as.formula(paste(s, "~ return_market")), data = returns_reg)
  tidy(model) %>%
    filter(term %in% c("(Intercept)", "return_market")) %>%
    select(term, estimate, p.value) %>%
    pivot_wider(names_from = term, values_from = c(estimate, p.value)) %>%
    mutate(stock = s,
           r2 = summary(model)$r.squared)
    
}) %>% bind_rows()

reg_output <- reg_output %>%
  rename(
    Ticker = stock,
    Alpha = `estimate_(Intercept)`,
    Beta = estimate_return_market,
    p_value_int = `p.value_(Intercept)`,
    p_value = p.value_return_market,
    R2 = r2
  ) %>%
  select(Ticker, Alpha, Beta, p_value_int, p_value, R2)

reg_output %>%
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>%
  kable()

# boxplots für beta und r2
reg_long <- reg_output %>%
  select(Beta, R2) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value")

p_box <- ggplot(reg_long, aes(x = metric, y = value)) +
  geom_boxplot(
    fill = "#1599AB",
    alpha = 0.8,
    width = 0.5
  ) +
  geom_jitter(width = 0.05, alpha = 0.6) +
  facet_wrap(~metric, scales = "free", strip.position = "bottom") +
  labs(
    title = "Distribution of Market Model Estimates",
    x = "",
    y = ""
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_blank(),  
    axis.ticks.x = element_blank()  
  )
p_box
```

**Table 8** displays the results for each stock in the portfolio.

The Beta values show a clear split in the portfolio. The technology stocks are aggressive and amplify market movements. For example, Netflix ($\beta=1.30$) and Amazon ($\beta=1.27$) have Betas well above 1.0, meaning they tend to rise and fall much more than the market.

On the other hand, defensive stocks act as stabilizers. Coca-Cola ($\beta=0.32$) and Lockheed Martin ($\beta=0.34$) have very low sensitivity, meaning they are largely unaffected by daily market volatility.

The $R^2$ value tells us how closely a stock follows the market. For major tech companies like Apple, the $R^2$ is high ($0.59$). This suggests that nearly 60% of Apple's price movement is caused by general market trends rather than company-specific news.

The standout result is Eli Lilly (LLY). It has almost no correlation with the market ($R^2=0.045$) and a low Beta of 0.29. Most importantly, it is the only stock with a statistically significant Alpha of 2.1% per month. This proves that LLY's strong performance was driven by its own success (such as new drug launches) rather than just a rising stock market.

## Multifactor Model Results

While the single-factor model gave us a rough estimate of risk, it missed important details about investment "styles." To fix this, we used the **Fama-French 3-Factor Model**. This model breaks down returns into three specific sources of risk:

1.  **Market Risk** (Mkt-RF)

2.  **Size Risk** (SMB: Small Minus Big)

3.  **Value Risk** (HML: High Minus Low)

The regression equation used is:

\$$R_{i} - R_{f} = \alpha + \beta_{mkt}(R_{m} - R_{f}) + \beta_{smb}SMB + \beta_{hml}HML + \epsilon$

**Table 9** shows how each stock relates to these factors.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# import fama 3 factor | https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html
f3f <- read_csv("data/fama_3_factor.csv", skip = 3, col_names = TRUE)

f3f <- f3f %>%
  rename(ym = ...1) %>%
  mutate(date = as.Date(paste0(ym, "01"), format = "%Y%m%d"))

f3f <- f3f %>% select(date, `Mkt-RF`, SMB, HML, RF) %>% filter(date >= as.Date("2014-08-29"), date <= as.Date("2024-08-30")) %>% mutate(across(c(`Mkt-RF`, SMB, HML, RF), ~ .x / 100))

# monat und jahr aus datum extrahieren
returns_reg_new <- returns_reg %>%
  mutate(ym = format(month, "%Y-%m"))

f3f <- f3f %>%
  mutate(ym = format(date, "%Y-%m"))

# f3f und returns_reg_new zusammenführen
f3f <- returns_reg_new %>%
  left_join(f3f, by = "ym") %>%
  drop_na() %>%
  rename(Mkt_RF = `Mkt-RF`)

# ticker namen extrahieren

stocks_f3f <- setdiff(
  names(f3f),
  c("month", "date", "date.x", "date.y", "ym", "return_market", 
    "Mkt_RF", "SMB", "HML", "RF")
)


# multiple regression durchführen
ff3_results <- lapply(stocks_f3f, function(s) {

  # Excess Return der jeweiligen Aktie
  f3f_tmp <- f3f %>%
    mutate(excess = .data[[s]] - RF)

  model <- lm(excess ~ `Mkt_RF` + SMB + HML, data = f3f_tmp)

  # Koeffizienten + R² extrahieren
  tibble(
    Ticker = s,
    Alpha = coef(model)[["(Intercept)"]],
    Beta_mkt = coef(model)[["Mkt_RF"]],
    Beta_smb = coef(model)[["SMB"]],
    Beta_hml = coef(model)[["HML"]],
    R2 = summary(model)$r.squared
  )
}) %>%
  bind_rows()



kable(ff3_results)


```

```{r echo=FALSE, message=FALSE, warning=FALSE}
# boxplots für beta und r2

ff3_results_long <- ff3_results %>%
  select(Beta_mkt, Beta_smb, Beta_hml, R2) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value")

p_box <- ggplot(ff3_results_long, aes(x = metric, y = value)) +
  geom_boxplot(
    fill = "#1599AB",
    alpha = 0.8,
    width = 0.5
  ) +
  geom_jitter(width = 0.05, alpha = 0.6) +
  facet_wrap(~metric, scales = "free", strip.position = "bottom") +
  labs(
    title = "Distribution of Fama-French Factor Estimates",
    x = "",
    y = ""
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_blank(),  # Entfernt den doppelten Text
    axis.ticks.x = element_blank()  # Entfernt die kleinen Striche unten
  )
p_box

```

The most revealing outcome from **Table 9** concerns the investment style of the portfolio. The HML factor, which separates "Growth" from "Value" stocks, shows that the portfolio is heavily skewed toward aggressive Growth. Tech giants like Amazon and Netflix exhibit almost perfect negative scores of -0.98 and -0.97, respectively. This structural bias explains the severity of the 2022 crash; since Growth stocks are mathematically sensitive to interest rates, these assets collapsed not just because the market fell, but because their specific investment style stopped working when rates rose. The only significant counter-balance was Charles Schwab, which showed a positive score of 0.84, confirming its behavior as a traditional Value stock.

The analysis also highlights a clear split in company size through the SMB factor. Coca-Cola exhibits a strong negative score of -0.75, confirming that it acts as a "Mega-Cap" stabilizer that provides safety and lower volatility. In contrast, Old Dominion Freight Line shows a positive score of 0.51, indicating that it trades with the volatility and characteristics of a mid-sized company, adding a distinct layer of risk to the group despite its large size.

Finally, the most critical finding concerns Eli Lilly (LLY). While the simple market model suggested it was a top performer, the multifactor model confirms this was due to skill rather than luck. Even after subtracting the effects of the market rally, the size factor, and the growth style, Eli Lilly still retains a "True Alpha" of 1.94% per month. This proves that its returns were driven by idiosyncratic business success, such as new drug launches, rather than broad sector trends. This finding validates the optimization algorithm's decision to bet heavily on LLY, as it was the only asset generating significant profit completely independent of the economic cycle.

# Limitations

While the Optimized Portfolio was mathematically superior, it highlights a critical limitation of ex-post Mean-Variance Optimization: Hindsight Bias.

-   Concentration Risk: The model allocated nearly 37% of capital to a single stock (LLY). In a real-world scenario, this would be considered reckless risk management. If LLY’s clinical trials had failed, the portfolio’s performance would have been catastrophic.

-   Instability: The "optimal" weights are highly sensitive to the specific time period chosen. A slight change in the start or end date could drastically alter the suggested allocation.

Therefore, while the Tangency Portfolio serves as a powerful theoretical benchmark for what *was* possible, the Equal-Weighted portfolio likely represents a more realistic and robust strategy for an investor facing an uncertain future.

# Conclusion

This analysis of the financial markets from 2014 to 2024 offers clear lessons on the strengths and weaknesses of different investment strategies. By comparing a simple "naive" portfolio against a mathematically optimized one, we drew three major conclusions.

The Equal-Weighted ($1/N$) strategy proved that simply holding many stocks does not always guarantee safety. While this approach successfully protected against individual company failures (like Netflix’s crash), it failed to protect against the broader economic shift in 2022. Our regression analysis explains why: the portfolio was heavily packed with "Growth" stocks. Because these companies all share the same sensitivity to interest rates, diversification failed when rates rose, causing the entire basket to fall together.

The Tangency Portfolio significantly outperformed the naive strategy, especially during the crisis. It achieved this not by being more diversified, but by being more selective. The optimization algorithm correctly identified that holding Big Tech stocks (Amazon, Apple, Google) was redundant. Instead, it concentrated capital in Eli Lilly, which our models confirmed was the only asset with "True Alpha", profit generated by company success rather than market trends. This allowed the optimized portfolio to generate positive returns even when the rest of the market was falling.

Ultimately, this study highlights a conflict between math and reality. Theoretically, the optimized portfolio was superior because it successfully swapped market risk for specific company skill. However, in practice, allocating nearly 37% of a portfolio to a single stock is extremely dangerous. While the optimized strategy serves as a powerful example of what was possible in hindsight, the simple diversified portfolio likely remains the more robust choice for an investor facing an uncertain future.
